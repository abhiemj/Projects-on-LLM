{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":19018,"databundleVersionId":2703900,"sourceType":"competition"},{"sourceId":1005284,"sourceType":"datasetVersion","datasetId":551823}],"dockerImageVersionId":29860,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Load Data","metadata":{}},{"cell_type":"code","source":"# text = train['comment_text'][index]\n# text","metadata":{"execution":{"iopub.status.busy":"2023-11-27T05:19:14.961947Z","iopub.execute_input":"2023-11-27T05:19:14.962351Z","iopub.status.idle":"2023-11-27T05:19:14.966375Z","shell.execute_reply.started":"2023-11-27T05:19:14.962292Z","shell.execute_reply":"2023-11-27T05:19:14.965281Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# # import pandas as pd\n# # text = pd.DataFrame(train['comment_text'][:10])\n\n# from transformers import AutoTokenizer\n\n# tokenizer = AutoTokenizer.from_pretrained('distilbert-base-multilingual-cased')\n# train['comment_text'].map(tokenizer.encode_plus(,\n#                      None,\n#                      add_special_tokens =True,\n#                      max_length = 64,\n#                      pad_to_max_length = True,\n#                      return_token_type_ids = True)\n# input_","metadata":{"execution":{"iopub.status.busy":"2023-11-27T05:19:14.968237Z","iopub.execute_input":"2023-11-27T05:19:14.968807Z","iopub.status.idle":"2023-11-27T05:19:14.981894Z","shell.execute_reply.started":"2023-11-27T05:19:14.968549Z","shell.execute_reply":"2023-11-27T05:19:14.981167Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\n# read the train dataset\ntrain = pd.read_csv(r'/kaggle/input/jigsaw-multilingual-toxic-comment-classification/jigsaw-toxic-comment-train.csv')\n# Look at dataset\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-27T05:19:14.983109Z","iopub.execute_input":"2023-11-27T05:19:14.983401Z","iopub.status.idle":"2023-11-27T05:19:16.091279Z","shell.execute_reply.started":"2023-11-27T05:19:14.983362Z","shell.execute_reply":"2023-11-27T05:19:16.090472Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"                 id                                       comment_text  toxic  \\\n0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n\n   severe_toxic  obscene  threat  insult  identity_hate  \n0             0        0       0       0              0  \n1             0        0       0       0              0  \n2             0        0       0       0              0  \n3             0        0       0       0              0  \n4             0        0       0       0              0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>comment_text</th>\n      <th>toxic</th>\n      <th>severe_toxic</th>\n      <th>obscene</th>\n      <th>threat</th>\n      <th>insult</th>\n      <th>identity_hate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0000997932d777bf</td>\n      <td>Explanation\\nWhy the edits made under my usern...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000103f0d9cfb60f</td>\n      <td>D'aww! He matches this background colour I'm s...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>000113f07ec002fd</td>\n      <td>Hey man, I'm really not trying to edit war. It...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0001b41b1c6bb37e</td>\n      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0001d958c54c6e35</td>\n      <td>You, sir, are my hero. Any chance you remember...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"## Comment_text is our feature , which we will tokenize using bert toknizer \n## Toxic is our label\n\n## Load test and validation dataset\ntest = pd.read_csv(r'/kaggle/input/jigsaw-multilingual-toxic-comment-classification/test.csv')\nvalidation = pd.read_csv(r'/kaggle/input/jigsaw-multilingual-toxic-comment-classification/validation.csv')","metadata":{"execution":{"iopub.status.busy":"2023-11-27T05:19:16.094284Z","iopub.execute_input":"2023-11-27T05:19:16.094816Z","iopub.status.idle":"2023-11-27T05:19:16.506679Z","shell.execute_reply.started":"2023-11-27T05:19:16.094651Z","shell.execute_reply":"2023-11-27T05:19:16.505837Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"## Run code on small sample\ntrain = train[:1000]\nvalidation = validation[:1000]\ntest = test[:1000]","metadata":{"execution":{"iopub.status.busy":"2023-11-27T05:19:16.509324Z","iopub.execute_input":"2023-11-27T05:19:16.509697Z","iopub.status.idle":"2023-11-27T05:19:16.514425Z","shell.execute_reply.started":"2023-11-27T05:19:16.509642Z","shell.execute_reply":"2023-11-27T05:19:16.513547Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"## Set up TPU","metadata":{}},{"cell_type":"code","source":"# # Detect hardware, return appropriate distribution strategy\n# try:\n#     # TPU detection. No parameters necessary if TPU_NAME environment variable is\n#     # set: this is always the case on Kaggle.\n#     tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n#     print('Running on TPU ', tpu.master())\n# except ValueError:\n#     tpu = None\n\n# if tpu:\n#     tf.config.experimental_connect_to_cluster(tpu)\n#     tf.tpu.experimental.initialize_tpu_system(tpu)\n#     strategy = tf.distribute.experimental.TPUStrategy(tpu)\n# else:\n#     # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n#     strategy = tf.distribute.get_strategy()\n\n# print(\"REPLICAS: \", strategy.num_replicas_in_sync)","metadata":{"execution":{"iopub.status.busy":"2023-11-27T05:19:16.516188Z","iopub.execute_input":"2023-11-27T05:19:16.516766Z","iopub.status.idle":"2023-11-27T05:19:16.525952Z","shell.execute_reply.started":"2023-11-27T05:19:16.516659Z","shell.execute_reply":"2023-11-27T05:19:16.524983Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing\n\nProcess individual sentences for input to BERT using the tokenizer, and then prepare the entire dataset. The same code will process the other training data files, as well as the validation and test data.\n\nWe need to clean the comment text feature , we will use NLTK library for cleaning the text , then use BERT MODEL TO TOKENIZE","metadata":{}},{"cell_type":"code","source":"# Make the text into lowercase \ntrain['comment_text'] = train['comment_text'].apply(lambda x : str(x).lower())\n\n","metadata":{"execution":{"iopub.status.busy":"2023-11-27T05:19:16.527159Z","iopub.execute_input":"2023-11-27T05:19:16.527500Z","iopub.status.idle":"2023-11-27T05:19:16.540673Z","shell.execute_reply.started":"2023-11-27T05:19:16.527452Z","shell.execute_reply":"2023-11-27T05:19:16.539907Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"## Check if it is lowercase\ntrain['comment_text'][:4]","metadata":{"execution":{"iopub.status.busy":"2023-11-27T05:19:16.541773Z","iopub.execute_input":"2023-11-27T05:19:16.542112Z","iopub.status.idle":"2023-11-27T05:19:16.556675Z","shell.execute_reply.started":"2023-11-27T05:19:16.542066Z","shell.execute_reply":"2023-11-27T05:19:16.555530Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"0    explanation\\nwhy the edits made under my usern...\n1    d'aww! he matches this background colour i'm s...\n2    hey man, i'm really not trying to edit war. it...\n3    \"\\nmore\\ni can't make any real suggestions on ...\nName: comment_text, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"## Remove stopwords\nimport nltk\nfrom nltk.corpus import stopwords\n\nstopword = stopwords.words('english')\n\n## define a for loop to get function\ndef remove_stopwords(txt):\n    words = txt.split(' ')\n    filtered_word = []\n    for word in words:\n        if word not in stopword:\n            filtered_word.append(word)\n    return ' '.join(filtered_word)\n\n        \n        ","metadata":{"execution":{"iopub.status.busy":"2023-11-27T05:19:16.557913Z","iopub.execute_input":"2023-11-27T05:19:16.558248Z","iopub.status.idle":"2023-11-27T05:19:17.886137Z","shell.execute_reply.started":"2023-11-27T05:19:16.558199Z","shell.execute_reply":"2023-11-27T05:19:17.885246Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"print(f\"Text in the first row is {train['comment_text'][:1]} \\n\")\nword = train['comment_text'][:1].apply(remove_stopwords)\nprint(f\"Text in the first row after removing stop word is {word}\")\n      ","metadata":{"execution":{"iopub.status.busy":"2023-11-27T05:19:17.887586Z","iopub.execute_input":"2023-11-27T05:19:17.888011Z","iopub.status.idle":"2023-11-27T05:19:17.904009Z","shell.execute_reply.started":"2023-11-27T05:19:17.887949Z","shell.execute_reply":"2023-11-27T05:19:17.903211Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Text in the first row is 0    explanation\\nwhy the edits made under my usern...\nName: comment_text, dtype: object \n\nText in the first row after removing stop word is 0    explanation\\nwhy edits made username hardcore ...\nName: comment_text, dtype: object\n","output_type":"stream"}]},{"cell_type":"code","source":"## Apply it in the dataset\ntrain['comment_text'] = train['comment_text'].apply(remove_stopwords)","metadata":{"execution":{"iopub.status.busy":"2023-11-27T05:19:17.905261Z","iopub.execute_input":"2023-11-27T05:19:17.905545Z","iopub.status.idle":"2023-11-27T05:19:18.062258Z","shell.execute_reply.started":"2023-11-27T05:19:17.905501Z","shell.execute_reply":"2023-11-27T05:19:18.061534Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"import re,string\n## Remove special Characters\n## define a function to clean the text\ndef clean_text(txt):\n    ## make it lowercase\n    txt = str(txt).lower()\n    ## remove any sequence of characters in square brackets\n    ## remove special characters .*?\n    ## remove brackets hence use backlash \\[ , \\]\n    ## re.sub(pattern,replacement,string)\n    txt = re.sub('\\[.*?\\]','',txt)\n    ## remove links\n    txt =re.sub('https?://\\S+|www\\.\\S+','',txt)\n    ## remove HTML tags\n    txt = re.sub('<.*?>+','',txt)\n    ## remove punctuations\n    txt = re.sub('[%s]' % re.escape(string.punctuation),'',txt)\n    ## remove newline characters\n    txt = re.sub('\\n','',txt)\n    ## remove words containing numbers\n    txt = re.sub('\\w*\\d\\w*','',txt)\n    return txt","metadata":{"execution":{"iopub.status.busy":"2023-11-27T05:19:18.063424Z","iopub.execute_input":"2023-11-27T05:19:18.063768Z","iopub.status.idle":"2023-11-27T05:19:18.071425Z","shell.execute_reply.started":"2023-11-27T05:19:18.063690Z","shell.execute_reply":"2023-11-27T05:19:18.070374Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"train['comment_text'] = train['comment_text'].apply(clean_text)\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-27T05:19:18.072575Z","iopub.execute_input":"2023-11-27T05:19:18.072989Z","iopub.status.idle":"2023-11-27T05:19:18.213946Z","shell.execute_reply.started":"2023-11-27T05:19:18.072944Z","shell.execute_reply":"2023-11-27T05:19:18.213043Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"                 id                                       comment_text  toxic  \\\n0  0000997932d777bf  explanationwhy edits made username hardcore me...      0   \n1  000103f0d9cfb60f  daww matches background colour im seemingly st...      0   \n2  000113f07ec002fd  hey man im really trying edit war guy constant...      0   \n3  0001b41b1c6bb37e  morei cant make real suggestions improvement  ...      0   \n4  0001d958c54c6e35         you sir hero chance remember page thats on      0   \n\n   severe_toxic  obscene  threat  insult  identity_hate  \n0             0        0       0       0              0  \n1             0        0       0       0              0  \n2             0        0       0       0              0  \n3             0        0       0       0              0  \n4             0        0       0       0              0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>comment_text</th>\n      <th>toxic</th>\n      <th>severe_toxic</th>\n      <th>obscene</th>\n      <th>threat</th>\n      <th>insult</th>\n      <th>identity_hate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0000997932d777bf</td>\n      <td>explanationwhy edits made username hardcore me...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000103f0d9cfb60f</td>\n      <td>daww matches background colour im seemingly st...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>000113f07ec002fd</td>\n      <td>hey man im really trying edit war guy constant...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0001b41b1c6bb37e</td>\n      <td>morei cant make real suggestions improvement  ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0001d958c54c6e35</td>\n      <td>you sir hero chance remember page thats on</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"## clean the test and validation data aslo\ntest['lang'].unique()","metadata":{"execution":{"iopub.status.busy":"2023-11-27T05:19:18.215217Z","iopub.execute_input":"2023-11-27T05:19:18.215530Z","iopub.status.idle":"2023-11-27T05:19:18.221668Z","shell.execute_reply.started":"2023-11-27T05:19:18.215477Z","shell.execute_reply":"2023-11-27T05:19:18.220925Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"array(['tr', 'ru', 'it', 'fr', 'pt', 'es'], dtype=object)"},"metadata":{}}]},{"cell_type":"code","source":"## we need to get the stopwords for all five languagee\n#append all the other languages stopwords\n\ntuk_stopwords = stopwords.words('turkish')\nrus_stopwords = stopwords.words('russian')\nital_stopwords = stopwords.words('italian')\nfrench_stopwords = stopwords.words('french')\nportugese_stopwords = stopwords.words('portuguese')\nspanish_stopwords = stopwords.words('spanish')\n\ntest_stopwords = tuk_stopwords + rus_stopwords + ital_stopwords + french_stopwords + portugese_stopwords + spanish_stopwords\n\n## define a funct to remove stopwords from test data\ndef test_stopword(txt):\n    words = txt.split(' ')\n    filtered_word = []\n    for word in words:\n        if word not in test_stopwords:\n            filtered_word.append(word)\n    return ' '.join(filtered_word)\n\n## remove stopwords from test data \ntest['content'] = test['content'].apply(test_stopword)\ntest['content'] = test['content'].apply(clean_text)","metadata":{"execution":{"iopub.status.busy":"2023-11-27T05:19:18.222993Z","iopub.execute_input":"2023-11-27T05:19:18.223311Z","iopub.status.idle":"2023-11-27T05:19:19.244051Z","shell.execute_reply.started":"2023-11-27T05:19:18.223268Z","shell.execute_reply":"2023-11-27T05:19:19.242504Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-27T05:19:19.245732Z","iopub.execute_input":"2023-11-27T05:19:19.246151Z","iopub.status.idle":"2023-11-27T05:19:19.257173Z","shell.execute_reply.started":"2023-11-27T05:19:19.246090Z","shell.execute_reply":"2023-11-27T05:19:19.256181Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"   id                                            content lang\n0   0  doctor who adlı viki başlığına  doctor olarak ...   tr\n1   1   вполне возможно пока вижу необходимости выдел...   ru\n2   2  quindi   conservativi   preferiscono cancellar...   it\n3   3  malesef gerçekleştirilmedi ancak şöyle bir var...   tr\n4   4  resimseldabagcanjpg resminde kaynak sorunu    ...   tr","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>content</th>\n      <th>lang</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>doctor who adlı viki başlığına  doctor olarak ...</td>\n      <td>tr</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>вполне возможно пока вижу необходимости выдел...</td>\n      <td>ru</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>quindi   conservativi   preferiscono cancellar...</td>\n      <td>it</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>malesef gerçekleştirilmedi ancak şöyle bir var...</td>\n      <td>tr</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>resimseldabagcanjpg resminde kaynak sorunu    ...</td>\n      <td>tr</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"validation['lang'].unique()","metadata":{"execution":{"iopub.status.busy":"2023-11-27T05:19:19.258594Z","iopub.execute_input":"2023-11-27T05:19:19.258990Z","iopub.status.idle":"2023-11-27T05:19:19.269304Z","shell.execute_reply.started":"2023-11-27T05:19:19.258938Z","shell.execute_reply":"2023-11-27T05:19:19.268444Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"array(['es', 'it', 'tr'], dtype=object)"},"metadata":{}}]},{"cell_type":"code","source":"validation.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-27T05:19:19.270526Z","iopub.execute_input":"2023-11-27T05:19:19.270864Z","iopub.status.idle":"2023-11-27T05:19:19.286031Z","shell.execute_reply.started":"2023-11-27T05:19:19.270816Z","shell.execute_reply":"2023-11-27T05:19:19.285167Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"   id                                       comment_text lang  toxic\n0   0  Este usuario ni siquiera llega al rango de    ...   es      0\n1   1  Il testo di questa voce pare esser scopiazzato...   it      0\n2   2  Vale. Sólo expongo mi pasado. Todo tiempo pasa...   es      1\n3   3  Bu maddenin alt başlığı olarak  uluslararası i...   tr      0\n4   4  Belçika nın şehirlerinin yanında ilçe ve belde...   tr      0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>comment_text</th>\n      <th>lang</th>\n      <th>toxic</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Este usuario ni siquiera llega al rango de    ...</td>\n      <td>es</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Il testo di questa voce pare esser scopiazzato...</td>\n      <td>it</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Vale. Sólo expongo mi pasado. Todo tiempo pasa...</td>\n      <td>es</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Bu maddenin alt başlığı olarak  uluslararası i...</td>\n      <td>tr</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Belçika nın şehirlerinin yanında ilçe ve belde...</td>\n      <td>tr</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"## validation stopwords\nvalidation_stopword = tuk_stopwords + ital_stopwords + spanish_stopwords\n\ndef valid_stop(txt):\n    words = txt.split(' ')\n    filtered_word = []\n    for word in words:\n        if word not in validation_stopword:\n            filtered_word.append(word)\n    return ' '.join(filtered_word)\n\nvalidation['comment_text'] = validation['comment_text'].apply(valid_stop)\nvalidation['comment_text'] = validation['comment_text'].apply(clean_text)\n\nvalidation.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-27T05:19:19.291655Z","iopub.execute_input":"2023-11-27T05:19:19.291955Z","iopub.status.idle":"2023-11-27T05:19:19.894995Z","shell.execute_reply.started":"2023-11-27T05:19:19.291916Z","shell.execute_reply":"2023-11-27T05:19:19.893817Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"   id                                       comment_text lang  toxic\n0   0  este usuario siquiera llega rango    hereje   ...   es      0\n1   1  il testo voce pare esser scopiazzato direttame...   it      0\n2   2  vale sólo expongo pasado todo tiempo pasado me...   es      1\n3   3  bu maddenin alt başlığı olarak  uluslararası i...   tr      0\n4   4  belçika nın şehirlerinin yanında ilçe beldeler...   tr      0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>comment_text</th>\n      <th>lang</th>\n      <th>toxic</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>este usuario siquiera llega rango    hereje   ...</td>\n      <td>es</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>il testo voce pare esser scopiazzato direttame...</td>\n      <td>it</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>vale sólo expongo pasado todo tiempo pasado me...</td>\n      <td>es</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>bu maddenin alt başlığı olarak  uluslararası i...</td>\n      <td>tr</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>belçika nın şehirlerinin yanında ilçe beldeler...</td>\n      <td>tr</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"## 1.Tokenization\nimport torch \nfrom transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained('distilbert-base-multilingual-cased')","metadata":{"execution":{"iopub.status.busy":"2023-11-27T05:19:19.896538Z","iopub.execute_input":"2023-11-27T05:19:19.896903Z","iopub.status.idle":"2023-11-27T05:19:27.928644Z","shell.execute_reply.started":"2023-11-27T05:19:19.896853Z","shell.execute_reply":"2023-11-27T05:19:27.927604Z"},"trusted":true},"execution_count":26,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466.0, style=ProgressStyle(description_…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25bc1e549c94470bb1b5639bf7f6c3d2"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=995526.0, style=ProgressStyle(descripti…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d5e4cce711ea4705b4ec9ab78d0d78f4"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"## encode the text\ntrain['comment_text'] = train['comment_text'].apply(lambda x : tokenizer.encode(x,add_special_tokens = True))","metadata":{"execution":{"iopub.status.busy":"2023-11-27T05:19:27.930400Z","iopub.execute_input":"2023-11-27T05:19:27.930797Z","iopub.status.idle":"2023-11-27T05:19:29.460067Z","shell.execute_reply.started":"2023-11-27T05:19:27.930737Z","shell.execute_reply":"2023-11-27T05:19:29.459154Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-27T05:19:29.461556Z","iopub.execute_input":"2023-11-27T05:19:29.461917Z","iopub.status.idle":"2023-11-27T05:19:29.482723Z","shell.execute_reply.started":"2023-11-27T05:19:29.461865Z","shell.execute_reply":"2023-11-27T05:19:29.481882Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"                 id                                       comment_text  toxic  \\\n0  0000997932d777bf  [101, 88840, 10874, 19275, 70971, 10107, 11019...      0   \n1  000103f0d9cfb60f  [101, 10143, 10874, 10874, 18258, 25903, 43361...      0   \n2  000113f07ec002fd  [101, 10261, 10157, 10817, 10211, 30181, 32862...      0   \n3  0001b41b1c6bb37e  [101, 10798, 10116, 10944, 10123, 13086, 13486...      0   \n4  0001d958c54c6e35  [101, 13028, 52523, 51670, 27893, 93161, 15975...      0   \n\n   severe_toxic  obscene  threat  insult  identity_hate  \n0             0        0       0       0              0  \n1             0        0       0       0              0  \n2             0        0       0       0              0  \n3             0        0       0       0              0  \n4             0        0       0       0              0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>comment_text</th>\n      <th>toxic</th>\n      <th>severe_toxic</th>\n      <th>obscene</th>\n      <th>threat</th>\n      <th>insult</th>\n      <th>identity_hate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0000997932d777bf</td>\n      <td>[101, 88840, 10874, 19275, 70971, 10107, 11019...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000103f0d9cfb60f</td>\n      <td>[101, 10143, 10874, 10874, 18258, 25903, 43361...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>000113f07ec002fd</td>\n      <td>[101, 10261, 10157, 10817, 10211, 30181, 32862...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0001b41b1c6bb37e</td>\n      <td>[101, 10798, 10116, 10944, 10123, 13086, 13486...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0001d958c54c6e35</td>\n      <td>[101, 13028, 52523, 51670, 27893, 93161, 15975...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"## take only two cilumns for new df, comment_text, toxic\nnew_train = train[['comment_text','toxic']]\nnew_train.head(2)","metadata":{"execution":{"iopub.status.busy":"2023-11-27T05:19:29.483875Z","iopub.execute_input":"2023-11-27T05:19:29.484261Z","iopub.status.idle":"2023-11-27T05:19:29.502157Z","shell.execute_reply.started":"2023-11-27T05:19:29.484208Z","shell.execute_reply":"2023-11-27T05:19:29.501339Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"                                        comment_text  toxic\n0  [101, 88840, 10874, 19275, 70971, 10107, 11019...      0\n1  [101, 10143, 10874, 10874, 18258, 25903, 43361...      0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>comment_text</th>\n      <th>toxic</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[101, 88840, 10874, 19275, 70971, 10107, 11019...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[101, 10143, 10874, 10874, 18258, 25903, 43361...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"## 2. padding\n## get the maximum length \nmax_len = 0\nfor i in new_train['comment_text'].values:\n    if len(i) > max_len:\n        max_len = len(i)","metadata":{"execution":{"iopub.status.busy":"2023-11-27T05:20:54.846526Z","iopub.execute_input":"2023-11-27T05:20:54.846905Z","iopub.status.idle":"2023-11-27T05:20:54.852587Z","shell.execute_reply.started":"2023-11-27T05:20:54.846861Z","shell.execute_reply":"2023-11-27T05:20:54.851668Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"# new_train['comment_text'].iloc[0]","metadata":{"execution":{"iopub.status.busy":"2023-11-27T05:20:54.854512Z","iopub.execute_input":"2023-11-27T05:20:54.854871Z","iopub.status.idle":"2023-11-27T05:20:54.865476Z","shell.execute_reply.started":"2023-11-27T05:20:54.854819Z","shell.execute_reply":"2023-11-27T05:20:54.864496Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"max_len = 512\n## now pad the tokens which are less than the max_len\npadded_rows = []\n\nfor i in new_train['comment_text'].values:\n        pad = [0] * (max_len - len(i))\n        padded_rows.append(i + pad)\n        ","metadata":{"execution":{"iopub.status.busy":"2023-11-27T05:20:54.866819Z","iopub.execute_input":"2023-11-27T05:20:54.867233Z","iopub.status.idle":"2023-11-27T05:20:54.884758Z","shell.execute_reply.started":"2023-11-27T05:20:54.867170Z","shell.execute_reply":"2023-11-27T05:20:54.883918Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"new_train['comment_text'] = padded_rows","metadata":{"execution":{"iopub.status.busy":"2023-11-27T05:20:54.887300Z","iopub.execute_input":"2023-11-27T05:20:54.887831Z","iopub.status.idle":"2023-11-27T05:20:54.946907Z","shell.execute_reply.started":"2023-11-27T05:20:54.887650Z","shell.execute_reply":"2023-11-27T05:20:54.945827Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \"\"\"Entry point for launching an IPython kernel.\n","output_type":"stream"}]},{"cell_type":"code","source":"## check first row for padding\nnew_train['comment_text'][1][-10:]","metadata":{"execution":{"iopub.status.busy":"2023-11-27T05:20:54.948755Z","iopub.execute_input":"2023-11-27T05:20:54.949170Z","iopub.status.idle":"2023-11-27T05:20:54.958529Z","shell.execute_reply.started":"2023-11-27T05:20:54.949111Z","shell.execute_reply":"2023-11-27T05:20:54.957690Z"},"trusted":true},"execution_count":50,"outputs":[{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"},"metadata":{}}]},{"cell_type":"code","source":"## 3. Masking\n## we need to tell bert to ignore(mask) the padding we have added\n## when processing the input\n\nattention_mask = np.where(new_train['comment_text'] != 0,1,0)\nattention_mask.shape","metadata":{"execution":{"iopub.status.busy":"2023-11-27T05:20:54.959789Z","iopub.execute_input":"2023-11-27T05:20:54.960185Z","iopub.status.idle":"2023-11-27T05:20:54.970775Z","shell.execute_reply.started":"2023-11-27T05:20:54.960135Z","shell.execute_reply":"2023-11-27T05:20:54.970050Z"},"trusted":true},"execution_count":51,"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"(1000,)"},"metadata":{}}]},{"cell_type":"code","source":"## create tensor for model inputs\ninput_ids = torch.tensor(new_train['comment_text'])\nattention_mask = torch.tensor(attention_mask)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-11-27T05:20:54.971985Z","iopub.execute_input":"2023-11-27T05:20:54.972381Z","iopub.status.idle":"2023-11-27T05:20:55.058992Z","shell.execute_reply.started":"2023-11-27T05:20:54.972324Z","shell.execute_reply":"2023-11-27T05:20:55.058367Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"import transformers\n## feed into the model to get predictions\nmodel = transformers.DistilBertModel.from_pretrained('distilbert-base-multilingual-cased')\n","metadata":{"execution":{"iopub.status.busy":"2023-11-27T05:20:55.060195Z","iopub.execute_input":"2023-11-27T05:20:55.060525Z","iopub.status.idle":"2023-11-27T05:20:57.494041Z","shell.execute_reply.started":"2023-11-27T05:20:55.060465Z","shell.execute_reply":"2023-11-27T05:20:57.492745Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"## Model 1 \n## get predictions without training\n# with ctrategy.scope():\nwith torch.no_grad():\n    last_hidden_states = model(input_ids,attention_mask = attention_mask)","metadata":{"execution":{"iopub.status.busy":"2023-11-27T05:20:57.495837Z","iopub.execute_input":"2023-11-27T05:20:57.496290Z","iopub.status.idle":"2023-11-27T05:20:58.418502Z","shell.execute_reply.started":"2023-11-27T05:20:57.496222Z","shell.execute_reply":"2023-11-27T05:20:58.415996Z"},"trusted":true},"execution_count":54,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-54-1ebf25048c37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# with ctrategy.scope():\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mlast_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/transformers/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m             \u001b[0minputs_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (bs, seq_length, dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m         \u001b[0mtfmr_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m         \u001b[0mhidden_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfmr_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/transformers/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mword_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (bs, max_seq_length, dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0mposition_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (bs, max_seq_length, dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_embeddings\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mposition_embeddings\u001b[0m  \u001b[0;31m# (bs, max_seq_length, dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m         return F.embedding(\n\u001b[1;32m    113\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1482\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1483\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1484\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: index out of range: Tried to access index 512 out of table with 511 rows. at /opt/conda/conda-bld/pytorch_1579022034529/work/aten/src/TH/generic/THTensorEvenMoreMath.cpp:418"],"ename":"RuntimeError","evalue":"index out of range: Tried to access index 512 out of table with 511 rows. at /opt/conda/conda-bld/pytorch_1579022034529/work/aten/src/TH/generic/THTensorEvenMoreMath.cpp:418","output_type":"error"}]},{"cell_type":"markdown","source":"From here pass the hidden state througha linear function , then sigmoid function to get the final predicted class","metadata":{}},{"cell_type":"code","source":"## BERT does sentence classification it adds token called [CLS]","metadata":{"execution":{"iopub.status.busy":"2023-11-27T05:20:58.419439Z","iopub.status.idle":"2023-11-27T05:20:58.419992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"BERT does sentence classification it adds token called [CLS] (for classification) at begining of every sentence, The output corresponding to that token can be related as an embedding of rntire sentence\n\nFrom here we can use logistic regression using the [CLS] embedding layer as features and labels of our dataset, \nThis is a way without fine tuninng the bert model \nwe will do this approach later , for now lets move to pytorch architechture to fine tune your bert model  accrdng to our dataset and then ask it to classify\n","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## APPROACH 2  BERT TOKENIZER\n**Using pytorch transformer library**","metadata":{}},{"cell_type":"code","source":"## import Libraries\nimport pandas as pd\nimport torch\nimport transformers\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn as nn\nfrom transformers import DistilBertModel, DistilBertTokenizer,AutoTokenizer\nfrom sklearn import metrics\nfrom tqdm import tqdm\nimport numpy as np\nfrom torch import cuda","metadata":{"execution":{"iopub.status.busy":"2023-11-27T05:20:58.421279Z","iopub.status.idle":"2023-11-27T05:20:58.422024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Setup device\n## clean Dataset\n## Create class for dataset\n## define training and validation parameters\n## define class modeule for model\n## define loss function\n## define optimizer\n## define evaluate function\n## Run training loop\n## get the predictions output and evaluation score\n## create a submission file","metadata":{"execution":{"iopub.status.busy":"2023-11-27T05:20:58.423004Z","iopub.status.idle":"2023-11-27T05:20:58.423604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Setup device\n# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice = torch.device('cpu')\n## take 500 rows to run the code\n# train = train[:500]","metadata":{"execution":{"iopub.status.busy":"2023-11-27T05:20:58.424627Z","iopub.status.idle":"2023-11-27T05:20:58.425302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nprint(\"Is CUDA available: \", torch.cuda.is_available())\nprint(\"CUDA version: \", torch.version.cuda)\nprint(device)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-27T05:20:58.426260Z","iopub.status.idle":"2023-11-27T05:20:58.426919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## define key cariables \nMAX_LEN = max(train['comment_text'].apply(len))\nBATCH_SIZE = 16\nEPOCHS = 1\nLEARNING_RATE = 0.001\n\ntokenizer = AutoTokenizer.from_pretrained('distilbert-base-multilingual-cased')\n                                         ","metadata":{"execution":{"iopub.status.busy":"2023-11-27T05:20:58.427869Z","iopub.status.idle":"2023-11-27T05:20:58.428395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Class for creating dataset\n\nclass multilingual_dataset(Dataset):\n    def __init__(self, dataframe,tokenizer,max_len):\n        self.data = dataframe\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n    \n    def __getitem__(self,index):\n        text = str(self.data.comment_text[index])\n        inputs = tokenizer.encode_plus(text = text,\n                             text_pair = None,\n                                 add_special_tokens = True,\n                                 max_length = self.max_len,\n                                 pad_to_max_length = True,\n                                 return_token_type_ids = True,\n                                 return_attention_mask = True,\n                                       truncation_strategy = 'longest_first'\n                                )\n        idx = inputs['input_ids']\n        mask = inputs[\"attention_mask\"]\n        return   {\n            'ids': torch.tensor(idx, dtype = torch.long), # 64 bit integer\n            'mask' : torch.tensor(mask, dtype = torch.long), # 64 bit integer\n            'targets' : torch.tensor(self.data.toxic[index], dtype = torch.float32)\n            \n        }\n    def __len__(self):\n        return len(self.data)\n        ","metadata":{"execution":{"iopub.status.busy":"2023-11-27T05:20:58.429420Z","iopub.status.idle":"2023-11-27T05:20:58.430005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MAX_LEN","metadata":{"execution":{"iopub.status.busy":"2023-11-27T05:20:58.430965Z","iopub.status.idle":"2023-11-27T05:20:58.431443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_set = multilingual_dataset(train,tokenizer,512)\nvalidation_set = multilingual_dataset(validation,tokenizer,512)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-27T05:20:58.432428Z","iopub.status.idle":"2023-11-27T05:20:58.433095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## load data into dataloader\nfrom torch.utils.data import DataLoader\ntrain_data = DataLoader(dataset = training_set,\n                       batch_size=10,\n                       num_workers = 2)\nvalid_data = DataLoader(dataset = validation_set,\n                       batch_size=10,\n                       num_workers = 2)","metadata":{"execution":{"iopub.status.busy":"2023-11-27T05:20:58.434114Z","iopub.status.idle":"2023-11-27T05:20:58.434678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## constructor\n\n\nclass multilingual_bert_model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.bert = transformers.DistilBertModel.from_pretrained('distilbert-base-multilingual-cased')\n        self.drop = nn.Dropout(0.2)\n        self.linear = nn.Linear(768,1)\n        self.sigmoid = nn.Sigmoid()\n        \n    def forward(self,ids,mask):\n        model_output = self.bert(ids,mask)\n        hidden_state = model_output[0]\n        first_token_of_every_sentence = hidden_state[:,0,:] #all sentences, CLS position, all hidden unit outputs\n        output = self.drop(first_token_of_every_sentence)\n        linear_output = self.linear(output)\n        final_output = self.sigmoid(linear_output)\n        return final_output","metadata":{"execution":{"iopub.status.busy":"2023-11-27T05:20:58.435636Z","iopub.status.idle":"2023-11-27T05:20:58.436359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# instantiate model\nmodel = multilingual_bert_model()\n## put it on device\nmodel.to(device)\n# define loss function\nloss_fn = nn.BCELoss()\n\n# optimizer\noptimizer = torch.optim.Adam(model.parameters(),\n                            lr = 0.01)\n\n# define evaluation\nfrom sklearn.metrics import roc_auc_score\ndef roc_score(y_train,y_pred):\n    ## convert tensors to numpy\n    y_train = y_train.detach().cpu().to_numpy()\n    y_pred = y_pred.detach().cpu().to_numpy()\n    roc_score = roc_auc_score(y_train,y_pred)\n    return roc_score\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-11-27T05:20:58.437455Z","iopub.status.idle":"2023-11-27T05:20:58.438050Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for i,j in enumerate(train_data,0):\n#     print(j)","metadata":{"execution":{"iopub.status.busy":"2023-11-27T05:20:58.439078Z","iopub.status.idle":"2023-11-27T05:20:58.439643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 20\n\n\nfor epoch in range(epochs):\n    #train\n    model.train()\n    for _, data in enumerate(train_data):\n        ids = data['ids'].to(device,dtype = torch.long)\n        mask = data['mask'].to(device,dtype = torch.long)\n        y_train = data['targets'].to(device,dtype = torch.float)\n    # forward pas\n    y_pred = model(ids,mask).squeeze()\n    #calculate the loss\n    loss = loss_fn(y_pred,y_train)\n    #optimizer zero grad\n    optimizer.zero_grad()\n    #loss.backward\n    loss.backward()\n    # optimizer step\n    optimizer.step()\n    \n    ##testing\n    model.eval()\n    with torch.no_grad():\n        ## forwards pass\n        for _,Data in enumerate(valid_data):\n            idx = Data['ids'].to(device,dtype=torch.long)\n            Mask = Data['mask'].to(device,dtype=torch.long)\n            eval_y = Data['targets'].to(device,dtype=torch.float)\n            \n        eval_pred = model(ids = idx,mask = Mask)\n        # calculate loss\n        eval_loss = loss_fn(eval_pred,eval_y)\n    \n    #print whats happening\n    if epoch % 10 ==0:\n        print(f\"Epoch: {epoch} | train_loss {loss} | eval_loss {eval_loss}\")\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2023-11-27T05:20:58.440850Z","iopub.status.idle":"2023-11-27T05:20:58.441395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nprint(torch.cuda.is_available())\nprint(torch.cuda.get_device_name(0))\n","metadata":{"execution":{"iopub.status.busy":"2023-11-27T05:20:58.442408Z","iopub.status.idle":"2023-11-27T05:20:58.443049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" \nx = torch.tensor([1.0, 2.0]).cuda()\nprint(x)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-27T05:20:58.444242Z","iopub.status.idle":"2023-11-27T05:20:58.444803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# model.to(device)\n# Ensure your data tensors are also sent to the device\nmodel","metadata":{"execution":{"iopub.status.busy":"2023-11-27T05:20:58.445801Z","iopub.status.idle":"2023-11-27T05:20:58.446488Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]}]}